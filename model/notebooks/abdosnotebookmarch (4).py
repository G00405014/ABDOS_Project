# -*- coding: utf-8 -*-
"""AbdosNotebookMarch.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1MIZW4wFNhF-H7RPlQ6iyku6Ac-lA-hFI
"""

# CELL 1: Install Required Packages
# Install Required Packages
!pip install -q tensorflow seaborn scikit-learn pandas matplotlib tqdm

# CELL 2: Mount Google Drive and Import Libraries
# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive', force_remount=True)

# Import Required Libraries
import os
import time
import datetime
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import gc  # For garbage collection
from glob import glob
import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input, BatchNormalization
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.callbacks import (
    EarlyStopping, ReduceLROnPlateau, ModelCheckpoint, CSVLogger
)
from tensorflow.keras.optimizers import Adam, RMSprop, SGD
from sklearn.metrics import (
    classification_report, confusion_matrix, roc_curve, auc,
    precision_recall_curve, average_precision_score, f1_score,
    precision_score, recall_score, accuracy_score
)

# For reproducibility
SEED = 42
tf.random.set_seed(SEED)
np.random.seed(SEED)

print('TensorFlow version:', tf.__version__)

# CELL 3: Configuration and Paths Setup
# Configuration and Hyperparameters
BATCH_SIZE = 32
IMG_SIZE = (224, 224)  # Common input size for all models
NUM_CLASSES = 7        # Number of skin cancer classes

# Shortened training parameters
INITIAL_EPOCHS = 10    # Initial epochs (shortened)
FINE_TUNE_EPOCHS = 5   # Additional epochs for fine-tuning (shortened)

# Directories: Using specific paths for extracted folders and metadata
DATA_DIR_1 = "/content/drive/MyDrive/Dataset/extracted_part_1"
DATA_DIR_2 = "/content/drive/MyDrive/Dataset/extracted_part_2"
METADATA_PATH = "/content/drive/MyDrive/Dataset/HAM10000_metadata.csv"
MODEL_DIR = "/content/drive/MyDrive/Dataset/models"   # Folder to save models

# Create necessary subdirectories under MODEL_DIR
os.makedirs(MODEL_DIR, exist_ok=True)
LOGS_DIR = os.path.join(MODEL_DIR, "logs")
os.makedirs(LOGS_DIR, exist_ok=True)
METRICS_DIR = os.path.join(MODEL_DIR, "metrics")
os.makedirs(METRICS_DIR, exist_ok=True)
PLOTS_DIR = os.path.join(MODEL_DIR, "plots")
os.makedirs(PLOTS_DIR, exist_ok=True)

AUTOTUNE = tf.data.AUTOTUNE

print(f"Using data from: {DATA_DIR_1} and {DATA_DIR_2}")
print(f"Using metadata from: {METADATA_PATH}")
print(f"Results will be saved to: {MODEL_DIR}")

# Verify paths exist
for path in [DATA_DIR_1, DATA_DIR_2]:
    if os.path.exists(path):
        print(f"Path exists: {path}")
    else:
        print(f"Path not found: {path}")

# CELL 4: Metadata Loading and Analysis
# Find the metadata file
potential_metadata_paths = [
    METADATA_PATH,
    "/content/drive/MyDrive/Dataset/HAM10000_metadata.csv",
    "/content/drive/MyDrive/HAM10000_metadata.csv"
]

metadata_path = None
for path in potential_metadata_paths:
    if os.path.exists(path):
        metadata_path = path
        print(f"Found metadata at: {path}")
        METADATA_PATH = path
        break

if not metadata_path:
    print("Metadata file not found! Searching the Dataset folder...")
    # Search for any CSV file
    csv_files = glob("/content/drive/MyDrive/Dataset/**/*.csv", recursive=True)
    if csv_files:
        metadata_path = csv_files[0]
        METADATA_PATH = metadata_path
        print(f"Found potential metadata at: {metadata_path}")
    else:
        print("No CSV files found!")

# Load metadata if found
if metadata_path:
    metadata_df = pd.read_csv(metadata_path)
    print(f"Metadata loaded with {len(metadata_df)} entries")

    # Display metadata statistics
    print("\nClass distribution in metadata:")
    print(metadata_df['dx'].value_counts())

    # Class distribution plot in its own cell (to be executed in the next cell)
else:
    print("No metadata found. Cannot proceed.")

# CELL 5: Visualize Class Distribution in Metadata
# Plot class distribution
if 'metadata_df' in locals():
    plt.figure(figsize=(10, 6))
    sns.countplot(y=metadata_df['dx'], order=metadata_df['dx'].value_counts().index)
    plt.title('Diagnosis Distribution')
    plt.xlabel('Count')
    plt.ylabel('Diagnosis')
    plt.tight_layout()
    plt.savefig(os.path.join(PLOTS_DIR, "diagnosis_distribution.png"))
    plt.show()

    # Create metadata dictionary for quick lookup
    metadata_dict = metadata_df.set_index('image_id').to_dict(orient='index')

# CELL 6: Dataset Creation with Metadata
def create_dataset_from_metadata(metadata_path, image_dirs, img_size=IMG_SIZE, batch_size=BATCH_SIZE, seed=SEED):
    """Create a TensorFlow dataset using the HAM10000 metadata file to assign labels"""
    print(f"Loading metadata from: {metadata_path}")

    # Load metadata
    try:
        metadata_df = pd.read_csv(metadata_path)
        print(f"Loaded metadata with {len(metadata_df)} entries")
    except Exception as e:
        print(f"Error loading metadata: {e}")
        raise ValueError("Failed to load metadata")

    # Check necessary columns
    if 'image_id' not in metadata_df.columns or 'dx' not in metadata_df.columns:
        print(f"Metadata missing required columns. Found: {metadata_df.columns.tolist()}")
        raise ValueError("Metadata missing required columns")

    # Get class information
    class_names = sorted(metadata_df['dx'].unique())
    class_indices = {name: i for i, name in enumerate(class_names)}
    print(f"Found {len(class_names)} classes: {class_names}")

    # Find all image files in the directories
    all_image_paths = []
    for img_dir in image_dirs:
        if os.path.exists(img_dir):
            for ext in ['.jpg', '.jpeg', '.png', '.bmp', '.gif']:
                all_image_paths.extend(glob(os.path.join(img_dir, f"**/*{ext}"), recursive=True))
                all_image_paths.extend(glob(os.path.join(img_dir, f"**/*{ext.upper()}"), recursive=True))

    print(f"Found {len(all_image_paths)} image files")

    # Match images to metadata
    valid_paths = []
    valid_labels = []

    for img_path in all_image_paths:
        # Extract image_id from filename
        filename = os.path.basename(img_path)
        image_id = os.path.splitext(filename)[0]

        # Find in metadata
        matching_rows = metadata_df[metadata_df['image_id'] == image_id]
        if not matching_rows.empty:
            dx = matching_rows.iloc[0]['dx']
            label_idx = class_indices[dx]

            valid_paths.append(img_path)
            valid_labels.append(label_idx)

    print(f"Matched {len(valid_paths)} images with metadata")

    if not valid_paths:
        raise ValueError("No images could be matched with metadata")

    # Function to load and preprocess an image
    def load_and_preprocess_image(img_path, label):
        img = tf.io.read_file(img_path)
        img = tf.image.decode_jpeg(img, channels=3)
        img = tf.image.resize(img, img_size)
        return img, label

    # Create TensorFlow datasets
    path_ds = tf.data.Dataset.from_tensor_slices(valid_paths)
    label_ds = tf.data.Dataset.from_tensor_slices(valid_labels)
    dataset = tf.data.Dataset.zip((path_ds, label_ds))

    # Apply preprocessing
    dataset = dataset.map(load_and_preprocess_image, num_parallel_calls=AUTOTUNE)

    # Shuffle the dataset
    dataset = dataset.shuffle(buffer_size=len(valid_paths), seed=seed)

    # Split into train/val/test
    total_size = len(valid_paths)
    train_size = int(0.6 * total_size)
    val_size = int(0.2 * total_size)

    train_ds = dataset.take(train_size)
    temp_ds = dataset.skip(train_size)
    val_ds = temp_ds.take(val_size)
    test_ds = temp_ds.skip(val_size)

    # Batch and prepare for training
    train_ds = train_ds.batch(batch_size).prefetch(AUTOTUNE)
    val_ds = val_ds.batch(batch_size).prefetch(AUTOTUNE)
    test_ds = test_ds.batch(batch_size).prefetch(AUTOTUNE)

    # Show distribution of classes
    label_counts = {}
    for label in valid_labels:
        label_counts[label] = label_counts.get(label, 0) + 1

    print("\nClass distribution:")
    for label_idx, count in label_counts.items():
        class_name = class_names[label_idx]
        print(f"  {class_name}: {count} images ({count/len(valid_labels)*100:.1f}%)")

    return train_ds, val_ds, test_ds, class_names

# Create datasets using the metadata
train_dataset, val_dataset, test_dataset, class_names = create_dataset_from_metadata(
    METADATA_PATH, [DATA_DIR_1, DATA_DIR_2]
)

print("\nClass names (diagnosis codes):")
for i, class_name in enumerate(class_names):
    print(f"   {i}: {class_name}")

# CELL 7: Data Augmentation
# Define enhanced data augmentation
data_augmentation = Sequential([
    tf.keras.layers.RandomFlip("horizontal_and_vertical"),
    tf.keras.layers.RandomRotation(0.2),
    tf.keras.layers.RandomZoom(0.2),
    tf.keras.layers.RandomContrast(0.2),
    tf.keras.layers.RandomBrightness(0.2),
], name="data_augmentation")

print("\nData augmentation pipeline created with enhanced transformations")

# CELL 8: Visualize Augmented Images
def visualize_augmentations(dataset, augmentation_model, num_examples=5):
    """Show examples of augmented images"""
    plt.figure(figsize=(12, 12))

    for images, labels in dataset.take(1):
        images = images[:num_examples]
        augmented_images = augmentation_model(images)

        for i in range(num_examples):
            # Original image
            plt.subplot(num_examples, 2, 2*i+1)
            plt.imshow(images[i].numpy().astype("uint8"))
            plt.title(f"Original: {class_names[labels[i]]}")
            plt.axis("off")

            # Augmented image
            plt.subplot(num_examples, 2, 2*i+2)
            plt.imshow(augmented_images[i].numpy().astype("uint8"))
            plt.title("Augmented")
            plt.axis("off")

    plt.tight_layout()
    plt.savefig(os.path.join(PLOTS_DIR, "augmented_examples.png"))
    plt.show()

# Show some augmented examples
visualize_augmentations(train_dataset, data_augmentation)

# CELL 9: MobileNetV2 Model Building
def build_mobilenet_model(optimizer_name="Adam"):
    """Build MobileNetV2 model for skin lesion classification"""
    input_shape = IMG_SIZE + (3,)  # Add channels dimension

    # Create unique layer names
    model_prefix = f"MobileNetV2_{optimizer_name}_"

    # Define model inputs
    inputs = Input(shape=input_shape, name=f"{model_prefix}input")

    # Apply data augmentation (only during training)
    x = data_augmentation(inputs)

    # Load MobileNetV2 base model
    base_model = MobileNetV2(include_top=False, weights='imagenet', input_shape=input_shape)
    preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input
    fine_tune_at = 100  # Layer to start fine-tuning from

    # Freeze the base model initially
    base_model.trainable = False

    # Preprocess the input
    x = preprocess_input(x)

    # Pass through the base model
    x = base_model(x, training=False)

    # Global pooling
    x = GlobalAveragePooling2D(name=f"{model_prefix}gap")(x)
    x = BatchNormalization(name=f"{model_prefix}bn1")(x)
    x = Dropout(0.5, name=f"{model_prefix}dropout1")(x)

    # Dense layers
    x = Dense(512, activation='relu', name=f"{model_prefix}dense1")(x)
    x = BatchNormalization(name=f"{model_prefix}bn2")(x)
    x = Dropout(0.3, name=f"{model_prefix}dropout2")(x)

    x = Dense(256, activation='relu', name=f"{model_prefix}dense2")(x)
    x = BatchNormalization(name=f"{model_prefix}bn3")(x)
    x = Dropout(0.3, name=f"{model_prefix}dropout3")(x)

    # Output layer
    outputs = Dense(NUM_CLASSES, activation='softmax', name=f"{model_prefix}output")(x)

    # Create model
    model = Model(inputs, outputs, name=f"MobileNetV2_{optimizer_name}")

    # Select optimizer with appropriate learning rate
    if optimizer_name == "Adam":
        optimizer = Adam(learning_rate=0.001)
    elif optimizer_name == "RMSprop":
        optimizer = RMSprop(learning_rate=0.001)
    elif optimizer_name == "SGD":
        optimizer = SGD(learning_rate=0.001, momentum=0.9)
    else:
        raise ValueError(f"Unknown optimizer: {optimizer_name}")

    # Compile model
    model.compile(
        optimizer=optimizer,
        loss='sparse_categorical_crossentropy',
        metrics=[
            'accuracy',
            tf.keras.metrics.SparseTopKCategoricalAccuracy(k=3, name='top3_accuracy'),
            tf.keras.metrics.SparseCategoricalAccuracy(name='categorical_accuracy')
        ]
    )

    return model, base_model, fine_tune_at, optimizer_name

# CELL 10: Setup Callbacks
def setup_callbacks(optimizer_name):
    """Create callbacks for training"""
    # Define paths for this model
    model_subdir = f"MobileNetV2_{optimizer_name}"
    model_path = os.path.join(MODEL_DIR, model_subdir)
    log_path = os.path.join(LOGS_DIR, model_subdir)

    # Ensure directories exist
    os.makedirs(model_path, exist_ok=True)
    os.makedirs(log_path, exist_ok=True)

    # Create a timestamp for this training run
    timestamp = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")

    callbacks = [
        # Early stopping to prevent overfitting
        EarlyStopping(
            monitor='val_loss',
            patience=3,  # Reduced for shorter training
            restore_best_weights=True,
            verbose=1
        ),

        # Reduce learning rate when a metric has stopped improving
        ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.2,
            patience=2,  # Reduced for shorter training
            min_lr=1e-6,
            verbose=1
        ),

        # Save the best weights only, not the full model
        ModelCheckpoint(
            filepath=os.path.join(model_path, f"best_weights_{timestamp}.weights.h5"),
            monitor='val_categorical_accuracy',
            save_best_only=True,
            save_weights_only=True,
            verbose=1
        ),

        # CSV Logger
        CSVLogger(
            os.path.join(model_path, f"training_log_{timestamp}.csv"),
            append=True
        )
    ]

    return callbacks, model_path, timestamp

# CELL 11: Training Function
def train_mobilenet_model(optimizer_name="Adam"):
    """Train MobileNetV2 model on skin lesion dataset"""
    print(f"\n{'='*20} Training MobileNetV2 with {optimizer_name} {'='*20}")

    # Build the model
    model, base_model, fine_tune_at, optimizer_name = build_mobilenet_model(optimizer_name)
    print(f"Model built: {model.name}")

    # Set up callbacks
    callbacks, model_path, timestamp = setup_callbacks(optimizer_name)

    # Record start time
    start_time = time.time()

    # Phase 1: Train with frozen base model
    print(f"\nPhase 1: Training with frozen base model for {INITIAL_EPOCHS} epochs")
    history = model.fit(
        train_dataset,
        epochs=INITIAL_EPOCHS,
        validation_data=val_dataset,
        callbacks=callbacks
    )

    # Record time after initial training
    phase1_time = time.time() - start_time
    print(f"Phase 1 training completed in {phase1_time:.2f} seconds")

    # Phase 2: Fine-tuning
    print(f"\nPhase 2: Fine-tuning from layer {fine_tune_at} for {FINE_TUNE_EPOCHS} epochs")

    # Unfreeze layers for fine-tuning
    base_model.trainable = True
    for layer in base_model.layers[:fine_tune_at]:
        layer.trainable = False

    # Lower learning rate for fine-tuning
    if optimizer_name == "Adam":
        optimizer = Adam(learning_rate=1e-5)
    elif optimizer_name == "RMSprop":
        optimizer = RMSprop(learning_rate=1e-5)
    elif optimizer_name == "SGD":
        optimizer = SGD(learning_rate=1e-5, momentum=0.9)

    # Recompile with lower learning rate
    model.compile(
        optimizer=optimizer,
        loss='sparse_categorical_crossentropy',
        metrics=[
            'accuracy',
            tf.keras.metrics.SparseTopKCategoricalAccuracy(k=3, name='top3_accuracy'),
            tf.keras.metrics.SparseCategoricalAccuracy(name='categorical_accuracy')
        ]
    )

    # Continue training with fine-tuning
    history_fine = model.fit(
        train_dataset,
        epochs=INITIAL_EPOCHS + FINE_TUNE_EPOCHS,
        initial_epoch=history.epoch[-1] + 1,
        validation_data=val_dataset,
        callbacks=callbacks
    )

    # Record time after fine-tuning
    total_time = time.time() - start_time
    phase2_time = total_time - phase1_time
    print(f"Phase 2 fine-tuning completed in {phase2_time:.2f} seconds")
    print(f"Total training time: {total_time:.2f} seconds")

    # Evaluate the model on the test set
    print("\nEvaluating model on test dataset...")
    test_loss, test_acc, test_top3_acc, test_cat_acc = model.evaluate(test_dataset)
    print(f"Test accuracy: {test_acc:.4f}")
    print(f"Test top-3 accuracy: {test_top3_acc:.4f}")

    # Save training history
    history_data = {
        'accuracy': history.history['accuracy'] + history_fine.history['accuracy'],
        'val_accuracy': history.history['val_accuracy'] + history_fine.history['val_accuracy'],
        'loss': history.history['loss'] + history_fine.history['loss'],
        'val_loss': history.history['val_loss'] + history_fine.history['val_loss'],
        'categorical_accuracy': history.history['categorical_accuracy'] + history_fine.history['categorical_accuracy'],
        'val_categorical_accuracy': history.history['val_categorical_accuracy'] + history_fine.history['val_categorical_accuracy'],
        'top3_accuracy': history.history['top3_accuracy'] + history_fine.history['top3_accuracy'],
        'val_top3_accuracy': history.history['val_top3_accuracy'] + history_fine.history['val_top3_accuracy']
    }

    # Save weights separately
    weights_path = os.path.join(model_path, f"final_weights_{timestamp}.weights.h5")
    try:
        model.save_weights(weights_path)
        print(f"Model weights saved to: {weights_path}")
    except Exception as e:
        print(f"Error saving weights: {e}")

    # Record metrics for later use
    metrics = {
        'model': f"MobileNetV2_{optimizer_name}",
        'test_loss': test_loss,
        'test_accuracy': test_acc,
        'test_top3_accuracy': test_top3_acc,
        'test_categorical_accuracy': test_cat_acc,
        'training_time_phase1': phase1_time,
        'training_time_phase2': phase2_time,
        'training_time_total': total_time
    }

    return model, history_data, metrics

# CELL 12: Plot Accuracy History
def plot_accuracy_history(history_data, optimizer_name):
    """Plot accuracy training history"""
    model_subdir = f"MobileNetV2_{optimizer_name}"
    plots_path = os.path.join(PLOTS_DIR, model_subdir)
    os.makedirs(plots_path, exist_ok=True)

    plt.figure(figsize=(10, 6))
    plt.plot(history_data['accuracy'], label='Training Accuracy')
    plt.plot(history_data['val_accuracy'], label='Validation Accuracy')

    # Add vertical line at the boundary between initial training and fine-tuning
    plt.axvline(x=INITIAL_EPOCHS-1, color='r', linestyle='--', label='Start Fine Tuning')

    plt.title(f'Accuracy - MobileNetV2 with {optimizer_name}')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(os.path.join(plots_path, "accuracy_history.png"))
    plt.show()

# CELL 13: Plot Loss History
def plot_loss_history(history_data, optimizer_name):
    """Plot loss training history"""
    model_subdir = f"MobileNetV2_{optimizer_name}"
    plots_path = os.path.join(PLOTS_DIR, model_subdir)
    os.makedirs(plots_path, exist_ok=True)

    plt.figure(figsize=(10, 6))
    plt.plot(history_data['loss'], label='Training Loss')
    plt.plot(history_data['val_loss'], label='Validation Loss')

    # Add vertical line at the boundary between initial training and fine-tuning
    plt.axvline(x=INITIAL_EPOCHS-1, color='r', linestyle='--', label='Start Fine Tuning')

    plt.title(f'Loss - MobileNetV2 with {optimizer_name}')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(os.path.join(plots_path, "loss_history.png"))
    plt.show()

# CELL 14: Plot Top-3 Accuracy History
def plot_top3_accuracy_history(history_data, optimizer_name):
    """Plot top-3 accuracy training history"""
    model_subdir = f"MobileNetV2_{optimizer_name}"
    plots_path = os.path.join(PLOTS_DIR, model_subdir)
    os.makedirs(plots_path, exist_ok=True)

    plt.figure(figsize=(10, 6))
    plt.plot(history_data['top3_accuracy'], label='Training Top-3 Accuracy')
    plt.plot(history_data['val_top3_accuracy'], label='Validation Top-3 Accuracy')

    # Add vertical line at the boundary between initial training and fine-tuning
    plt.axvline(x=INITIAL_EPOCHS-1, color='r', linestyle='--', label='Start Fine Tuning')

    plt.title(f'Top-3 Accuracy - MobileNetV2 with {optimizer_name}')
    plt.xlabel('Epoch')
    plt.ylabel('Top-3 Accuracy')
    plt.legend()
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(os.path.join(plots_path, "top3_accuracy_history.png"))
    plt.show()

# CELL 15: Get Predictions for Evaluation
def get_test_predictions(model):
    """Get predictions on test dataset for evaluation metrics"""
    y_true_batches = []
    y_pred_probs_batches = []

    for images, labels in test_dataset:
        pred_probs = model.predict(images)
        y_true_batches.append(labels.numpy())
        y_pred_probs_batches.append(pred_probs)

    # Concatenate batch predictions
    y_true = np.concatenate(y_true_batches)
    y_pred_probs = np.concatenate(y_pred_probs_batches)
    y_pred = np.argmax(y_pred_probs, axis=1)

    return y_true, y_pred_probs, y_pred

# CELL 16: Plot Confusion Matrix
def plot_confusion_matrix(y_true, y_pred, optimizer_name):
    """Plot and save confusion matrix"""
    model_subdir = f"MobileNetV2_{optimizer_name}"
    metrics_path = os.path.join(METRICS_DIR, model_subdir)
    os.makedirs(metrics_path, exist_ok=True)

    # Create confusion matrix
    cm = confusion_matrix(y_true, y_pred)

    # Raw counts confusion matrix
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
    plt.title(f'Confusion Matrix - MobileNetV2 with {optimizer_name}')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.tight_layout()
    plt.savefig(os.path.join(metrics_path, "confusion_matrix_counts.png"))
    plt.show()

    # Normalized confusion matrix
    plt.figure(figsize=(10, 8))
    cm_norm = cm.astype('float') / cm.sum(axis=1, keepdims=True)
    sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Blues', xticklabels=class_names, yticklabels=class_names)
    plt.title(f'Normalized Confusion Matrix - MobileNetV2 with {optimizer_name}')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.tight_layout()
    plt.savefig(os.path.join(metrics_path, "confusion_matrix_normalized.png"))
    plt.show()

# CELL 17: Enhanced ROC Curves
def plot_roc_curves(y_true, y_pred_probs, optimizer_name):
    """Plot ROC curves for each class with enhanced visualization"""
    model_subdir = f"MobileNetV2_{optimizer_name}"
    metrics_path = os.path.join(METRICS_DIR, model_subdir)
    os.makedirs(metrics_path, exist_ok=True)

    # Plot ROC curves with larger figure size
    plt.figure(figsize=(14, 12))

    # Compute ROC curve and ROC area for each class
    fpr = dict()
    tpr = dict()
    roc_auc = dict()

    for i, class_name in enumerate(class_names):
        fpr[i], tpr[i], _ = roc_curve(
            (y_true == i).astype(int),
            y_pred_probs[:, i]
        )
        roc_auc[i] = auc(fpr[i], tpr[i])

        # Plot ROC curve for this class with thicker lines
        plt.plot(
            fpr[i], tpr[i],
            lw=2.5,  # Increased line width
            label=f'{class_name} (AUC = {roc_auc[i]:.2f})'
        )

    # Add diagonal line for reference
    plt.plot([0, 1], [0, 1], 'k--', lw=2.5)

    # Set axis limits
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])

    # Increase font sizes for labels and title
    plt.xlabel('False Positive Rate', fontsize=16, fontweight='bold')
    plt.ylabel('True Positive Rate', fontsize=16, fontweight='bold')
    plt.title(f'ROC Curves - MobileNetV2 with {optimizer_name}', fontsize=18, fontweight='bold')

    # Increase tick label sizes
    plt.xticks(fontsize=14)
    plt.yticks(fontsize=14)

    # Enhance legend with larger font and better position
    plt.legend(loc="lower right", fontsize=14, framealpha=0.9)

    # Add grid for better readability
    plt.grid(True, linestyle='--', alpha=0.7)

    # Add a text annotation with mean AUC
    mean_auc = np.mean([roc_auc[i] for i in range(len(class_names))])
    plt.text(0.05, 0.05, f'Mean AUC = {mean_auc:.3f}',
             fontsize=14, fontweight='bold',
             bbox=dict(facecolor='white', alpha=0.9, boxstyle='round,pad=0.5'))

    plt.tight_layout()
    plt.savefig(os.path.join(metrics_path, "roc_curves.png"), dpi=300)
    plt.show()

    # Create a summary bar chart of AUC values
    plt.figure(figsize=(12, 8))

    # Sort classes by AUC for better visualization
    auc_values = [roc_auc[i] for i in range(len(class_names))]
    sorted_indices = np.argsort(auc_values)
    sorted_classes = [class_names[i] for i in sorted_indices]
    sorted_auc = [auc_values[i] for i in sorted_indices]

    # Create horizontal bar chart
    bars = plt.barh(sorted_classes, sorted_auc)

    # Color the bars based on AUC value
    for i, bar in enumerate(bars):
        val = sorted_auc[i]
        # Color gradient: red for low values, yellow for medium, green for high
        r = max(0, min(255, int(255 * (1 - val))))
        g = max(0, min(255, int(255 * val)))
        b = 50
        color_hex = '#{:02x}{:02x}{:02x}'.format(r, g, b)
        bar.set_color(color_hex)

    # Add text annotations with AUC values
    for i, v in enumerate(sorted_auc):
        plt.text(v + 0.01, i, f"{v:.3f}", va='center', fontsize=12, fontweight='bold')

    # Add vertical line for reference at 0.5 (random chance)
    plt.axvline(x=0.5, color='red', linestyle='--', alpha=0.7)

    # Add vertical line for mean AUC
    plt.axvline(x=mean_auc, color='green', linestyle='-', alpha=0.7)
    plt.text(mean_auc, -0.5, f"Mean AUC: {mean_auc:.3f}",
             ha='center', fontsize=12, fontweight='bold', color='green')

    # Configure plot
    plt.xlim([0, 1.05])
    plt.xlabel('Area Under ROC Curve (AUC)', fontsize=16, fontweight='bold')
    plt.ylabel('Class', fontsize=16, fontweight='bold')
    plt.title(f'AUC by Class - MobileNetV2 with {optimizer_name}', fontsize=18, fontweight='bold')
    plt.xticks(fontsize=14)
    plt.yticks(fontsize=14)
    plt.grid(axis='x', linestyle='--', alpha=0.7)

    plt.tight_layout()
    plt.savefig(os.path.join(metrics_path, "auc_by_class.png"), dpi=300)
    plt.show()

    return roc_auc

# CELL 18: Plot Precision-Recall Curves
def plot_precision_recall_curves(y_true, y_pred_probs, optimizer_name):
    """Plot precision-recall curves for each class"""
    model_subdir = f"MobileNetV2_{optimizer_name}"
    metrics_path = os.path.join(METRICS_DIR, model_subdir)
    os.makedirs(metrics_path, exist_ok=True)

    # Plot precision-recall curves
    plt.figure(figsize=(12, 10))

    # Compute precision-recall curve for each class
    precision_dict = dict()
    recall_dict = dict()
    avg_precision = dict()

    for i, class_name in enumerate(class_names):
        precision_dict[i], recall_dict[i], _ = precision_recall_curve(
            (y_true == i).astype(int),
            y_pred_probs[:, i]
        )
        avg_precision[i] = average_precision_score(
            (y_true == i).astype(int),
            y_pred_probs[:, i]
        )

        # Plot precision-recall curve for this class
        plt.plot(
            recall_dict[i], precision_dict[i],
            lw=2,
            label=f'{class_name} (AP = {avg_precision[i]:.2f})'
        )

    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('Recall')
    plt.ylabel('Precision')
    plt.title(f'Precision-Recall Curves - MobileNetV2 with {optimizer_name}')
    plt.legend(loc="lower left")
    plt.grid(True)
    plt.tight_layout()
    plt.savefig(os.path.join(metrics_path, "precision_recall_curves.png"))
    plt.show()

    return avg_precision

# CELL 19: Calculate and Display Performance Metrics
def calculate_performance_metrics(y_true, y_pred, optimizer_name):
    """Calculate and display performance metrics"""
    model_subdir = f"MobileNetV2_{optimizer_name}"
    metrics_path = os.path.join(METRICS_DIR, model_subdir)

    # Calculate metrics
    accuracy = accuracy_score(y_true, y_pred)
    precision = precision_score(y_true, y_pred, average='weighted')
    recall = recall_score(y_true, y_pred, average='weighted')
    f1 = f1_score(y_true, y_pred, average='weighted')

    print(f"\nPerformance Metrics for MobileNetV2 with {optimizer_name}:")
    print(f"   Accuracy:  {accuracy:.4f}")
    print(f"   Precision: {precision:.4f}")
    print(f"   Recall:    {recall:.4f}")
    print(f"   F1 Score:  {f1:.4f}")

    # Generate classification report
    report = classification_report(y_true, y_pred, target_names=class_names, output_dict=True)
    report_df = pd.DataFrame(report).transpose()

    # Save the classification report
    report_df.to_csv(os.path.join(metrics_path, "classification_report.csv"))

    # Display classification report as table
    print("\nClassification Report:")
    print(report_df)

    # Save metrics as CSV for later reference
    metrics_df = pd.DataFrame({
        'Metric': ['Accuracy', 'Precision', 'Recall', 'F1 Score'],
        'Value': [accuracy, precision, recall, f1]
    })
    metrics_df.to_csv(os.path.join(metrics_path, "overall_metrics.csv"), index=False)

    return {
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1
    }

# CELL 20: Create Inference Function
def create_inference_code(optimizer_name):
    """Create and save an inference function for the model"""
    code = f"""
# Inference function for MobileNetV2 skin lesion classifier
import tensorflow as tf
import numpy as np
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input, BatchNormalization
from tensorflow.keras.applications import MobileNetV2
from tensorflow.keras.preprocessing import image

def build_model(num_classes=7, img_size=(224, 224)):
    '''Rebuild the model architecture for inference'''
    input_shape = img_size + (3,)

    # Define model inputs
    inputs = Input(shape=input_shape)

    # Load MobileNetV2 base model
    base_model = MobileNetV2(include_top=False, weights=None, input_shape=input_shape)

    # Pass through the base model
    x = base_model(inputs, training=False)

    # Global pooling
    x = GlobalAveragePooling2D()(x)
    x = BatchNormalization()(x)
    x = Dropout(0.5)(x)

    # Dense layers
    x = Dense(512, activation='relu')(x)
    x = BatchNormalization()(x)
    x = Dropout(0.3)(x)

    x = Dense(256, activation='relu')(x)
    x = BatchNormalization()(x)
    x = Dropout(0.3)(x)

    # Output layer
    outputs = Dense(num_classes, activation='softmax')(x)

    # Create model
    model = Model(inputs, outputs)
    return model

def load_and_preprocess_image(img_path, img_size=(224, 224)):
    '''Load and preprocess an image for inference'''
    img = image.load_img(img_path, target_size=img_size)
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)
    return img_array

def predict_skin_lesion(weights_path, img_path, class_names):
    '''Predict skin lesion from image'''
    # Build the model
    model = build_model()

    # Load weights
    model.load_weights(weights_path)

    # Preprocess the image
    processed_img = load_and_preprocess_image(img_path)

    # Make prediction
    predictions = model.predict(processed_img)
    predicted_class_idx = np.argmax(predictions[0])
    predicted_class = class_names[predicted_class_idx]
    confidence = predictions[0][predicted_class_idx] * 100

    # Get top 3 predictions
    top_indices = np.argsort(predictions[0])[-3:][::-1]
    top_predictions = [
        (class_names[i], predictions[0][i] * 100) for i in top_indices
    ]

    return predicted_class, confidence, top_predictions

# Example usage:
# weights_path = 'final_weights_YYYYMMDD-HHMMSS.weights.h5'
# img_path = 'path/to/your/skin_image.jpg'
# class_names = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']
#
# predicted_class, confidence, top_predictions = predict_skin_lesion(
#     weights_path, img_path, class_names)
# print(f"Predicted class: {{predicted_class}} with {{confidence:.2f}}% confidence")
# print("Top 3 predictions:")
# for class_name, conf in top_predictions:
#     print(f"  {{class_name}}: {{conf:.2f}}%")
"""

    # Save the inference code
    model_subdir = f"MobileNetV2_{optimizer_name}"
    model_path = os.path.join(MODEL_DIR, model_subdir)
    os.makedirs(model_path, exist_ok=True)

    with open(os.path.join(model_path, "inference_code.py"), "w") as f:
        f.write(code)

    print(f"Inference code saved to: {os.path.join(model_path, 'inference_code.py')}")

# CELL 21: Main Execution
def main():
    """Main execution function"""
    # Train model with different optimizers (choose which to use)
    optimizers_to_train = ["Adam"]  # Can also use "RMSprop" or "SGD"

    all_metrics = []

    for optimizer_name in optimizers_to_train:
        print(f"\nTraining MobileNetV2 with {optimizer_name} optimizer")

        # Train the model
        model, history_data, model_metrics = train_mobilenet_model(optimizer_name)

        # Plot training history in separate cells
        plot_accuracy_history(history_data, optimizer_name)
        plot_loss_history(history_data, optimizer_name)
        plot_top3_accuracy_history(history_data, optimizer_name)

        # Get predictions for evaluation
        y_true, y_pred_probs, y_pred = get_test_predictions(model)

        # Plot evaluation metrics in separate cells
        plot_confusion_matrix(y_true, y_pred, optimizer_name)
        roc_auc = plot_roc_curves(y_true, y_pred_probs, optimizer_name)
        avg_precision = plot_precision_recall_curves(y_true, y_pred_probs, optimizer_name)

        # Calculate performance metrics
        performance_metrics = calculate_performance_metrics(y_true, y_pred, optimizer_name)

        # Create inference code
        create_inference_code(optimizer_name)

        # Store metrics for comparison if needed
        all_metrics.append({
            'optimizer': optimizer_name,
            'performance': performance_metrics,
            'roc_auc': roc_auc,
            'avg_precision': avg_precision
        })

        print(f"\nCompleted training and evaluation of MobileNetV2 with {optimizer_name}")

    print("\nTraining and evaluation completed successfully!")
    print(f"Results are saved in: {MODEL_DIR}")

# Run the main function
if __name__ == "__main__":
    main()

# ADDITIONAL CELL: Save Complete Model (Run After Training)
# This cell can be run independently after the main training is complete
# No need to modify existing code

def save_complete_model_standalone():
    """Save the most recently trained model completely (architecture + weights + optimizer state)"""
    # Try to get the model from the global scope
    import gc
    import sys

    print("Looking for trained model to save...")

    # Find the most recently created model in memory
    model = None
    for obj in gc.get_objects():
        if isinstance(obj, tf.keras.Model) and hasattr(obj, 'name') and 'MobileNetV2' in obj.name:
            model = obj
            print(f"Found model: {model.name}")
            break

    if model is None:
        print("No MobileNetV2 model found in memory. Please run this cell right after training.")
        return

    # Get the optimizer name from the model name
    optimizer_name = model.name.split('_')[-1] if '_' in model.name else "Unknown"

    # Define paths
    model_subdir = f"MobileNetV2_{optimizer_name}"
    model_path = os.path.join(MODEL_DIR, model_subdir)
    os.makedirs(model_path, exist_ok=True)

    # Create a timestamp for this save
    timestamp = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")

    # Define save paths
    complete_model_path = os.path.join(model_path, f"complete_model_{timestamp}")
    savedmodel_path = os.path.join(model_path, f"savedmodel_{timestamp}")
    h5_path = os.path.join(model_path, f"model_{timestamp}.h5")

    # Save in different formats
    try:
        # Save complete model (default format)
        model.save(complete_model_path)
        print(f"✓ Complete model saved to: {complete_model_path}")

        # Save in SavedModel format
        tf.saved_model.save(model, savedmodel_path)
        print(f"✓ SavedModel format saved to: {savedmodel_path}")

        # Save in H5 format
        model.save(h5_path, save_format='h5')
        print(f"✓ H5 model saved to: {h5_path}")

        # Create example code for loading the model
        loading_code = f"""
# Example code to load the saved model:
import tensorflow as tf

# Method 1: Load the complete model (TensorFlow SavedModel format)
model = tf.keras.models.load_model('{complete_model_path}')

# Method 2: Load the h5 model file
model_h5 = tf.keras.models.load_model('{h5_path}')

# Make predictions with the loaded model
# predictions = model.predict(preprocessed_image)

# The following class names are used in the model:
class_names = {class_names if 'class_names' in globals() else ['Unknown']}
"""

        # Save the loading example
        with open(os.path.join(model_path, "model_loading_example.py"), "w") as f:
            f.write(loading_code)
        print(f"✓ Example loading code saved to: {os.path.join(model_path, 'model_loading_example.py')}")

        # Create a confirmation file that contains information about the saved model
        model_info = f"""
Model Information:
-----------------
Name: {model.name}
Optimizer: {optimizer_name}
Date Saved: {datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
File Formats:
  - TensorFlow SavedModel: {complete_model_path}
  - SavedModel Format: {savedmodel_path}
  - H5 Format: {h5_path}

Model Summary:
"""

        # Capture the model summary to a string
        import io
        summary_str = io.StringIO()
        model.summary(print_fn=lambda x: summary_str.write(x + '\n'))
        model_info += summary_str.getvalue()

        # Save the model info
        with open(os.path.join(model_path, f"model_info_{timestamp}.txt"), "w") as f:
            f.write(model_info)
        print(f"✓ Model information saved to: {os.path.join(model_path, f'model_info_{timestamp}.txt')}")

        print("\nModel saved successfully in multiple formats!")
        print("You can use these saved models for inference without rebuilding the architecture.")

    except Exception as e:
        print(f"⚠️ Error saving model: {e}")

# Run the standalone save function
save_complete_model_standalone()